{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dataset Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19)\n",
    "cpu_data_exists = False\n",
    "mem_data_exists = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cpu_data_exists:\n",
    "    cpu_data = np.load('google-cpu-full.npy')\n",
    "    np.random.shuffle(cpu_data)\n",
    "cpu_data_exists = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not mem_data_exists:\n",
    "    mem_data = np.load('google-mem-full.npy')\n",
    "    np.random.shuffle(mem_data)\n",
    "mem_data_exists = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are 12476 machines, each with 8351 datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_data.shape)\n",
    "print(mem_data.shape)\n",
    "\n",
    "assert cpu_data.shape == mem_data.shape\n",
    "\n",
    "no_of_machines = cpu_data.shape[0]\n",
    "no_of_timestamps = cpu_data.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We take a subsample of the machines. The dataset in its entirety is extremely\n",
    " large so for basic exploratory analysis it would burden us with too much\n",
    " computing workload without providing any further insight that is of\n",
    " significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_sample_size = 200\n",
    "cpu_spatial_sample = cpu_data[:spatial_sample_size]\n",
    "mem_spatial_sample = mem_data[:spatial_sample_size]\n",
    "\n",
    "cpu_spatial_correlations = np.empty(\n",
    "    (spatial_sample_size, spatial_sample_size-1))\n",
    "mem_spatial_correlations = np.empty(\n",
    "    (spatial_sample_size, spatial_sample_size-1))\n",
    "spatial_correlations = {\n",
    "    'CPU': cpu_spatial_correlations, 'MEM': mem_spatial_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_sample_size = 200\n",
    "cpu_temporal_sample = cpu_data[:temporal_sample_size]\n",
    "mem_temporal_sample = mem_data[:temporal_sample_size]\n",
    "\n",
    "cpu_temporal_correlations = np.empty(\n",
    "    (temporal_sample_size, 2*no_of_timestamps-1))\n",
    "mem_temporal_correlations = np.empty(\n",
    "    (temporal_sample_size, 2*no_of_timestamps-1))\n",
    "temporal_correlations = {\n",
    "    'CPU': cpu_temporal_correlations, 'MEM': mem_temporal_correlations}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be focusing on cpu and memory usage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121).plot(cpu_data[0])\n",
    "plt.title('CPU data')\n",
    "plt.subplot(122).plot(mem_data[0])\n",
    "plt.title('MEM data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccf(x, y, no_lag=False):\n",
    "    '''Normalized cross-correlation function,\n",
    "    similar to ccf in the R language.\n",
    "    \n",
    "    Parameters:\n",
    "    x -- first time series\n",
    "    y --  second time series\n",
    "    \n",
    "    Optional:\n",
    "    no_lag -- False by default. If true, return a list with every time-shift\n",
    "        possible instead.\n",
    "    \n",
    "    Returns:\n",
    "        A float with 0 time-shift or a list of floats that represent the\n",
    "        cross-correlation for every possible time-shift.\n",
    "    '''\n",
    "    correlation = (\n",
    "        np.correlate(y - np.mean(y), x - np.mean(x))\n",
    "        if no_lag else ss.correlate(y - np.mean(y), x - np.mean(x)))\n",
    "    \n",
    "    return correlation / (np.std(y) * np.std(x) * len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Spatial Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Calculate the spatial correlation between every possible pair of machines\n",
    " in our subsample. Do not include any time-shift. Do not include a machine's\n",
    " correlation with itself (by definition this will be 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(spatial_sample_size):\n",
    "    k=0\n",
    "    for j in range(spatial_sample_size):\n",
    "        #If the first and second machine are the same one, skip.\n",
    "        if i != j:\n",
    "            machine_x = cpu_spatial_sample[i]\n",
    "            machine_y = cpu_spatial_sample[j]\n",
    "            cpu_spatial_correlations[i, k] = ccf(machine_x,\n",
    "                                                 machine_y,\n",
    "                                                 no_lag=True)\n",
    "            machine_x = mem_spatial_sample[i]\n",
    "            machine_y = mem_spatial_sample[j]\n",
    "            mem_spatial_correlations[i, k] = ccf(machine_x,\n",
    "                                                 machine_y,\n",
    "                                                 no_lag=True)\n",
    "            k += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Have a look at how high the spatial correlation values seem to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for correlations in spatial_correlations:\n",
    "    abs_correlations = np.abs(spatial_correlations[correlations])\n",
    "    print(correlations, 'Absolute Maximum:', np.amax(abs_correlations))\n",
    "    print(correlations, 'Absolute Minimum:', np.amin(abs_correlations))\n",
    "    print(\n",
    "        correlations,\n",
    "        'Average:', np.average(spatial_correlations[correlations]))\n",
    "    print(correlations, 'RMS:', np.sqrt(np.mean(abs_correlations)))\n",
    "\n",
    "    plt.subplot(1, len(spatial_correlations), i).hist(\n",
    "        spatial_correlations[correlations],\n",
    "        bins=[n/10 for n in range(-10, 11)])\n",
    "    plt.title(correlations + ' Spatial Correlations')\n",
    "    plt.show()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Temporal Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Calculate the temporal correlation of each time series with itself, at every\n",
    " possible time-shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(temporal_sample_size):\n",
    "    cpu_temporal_correlations[i] = ccf(\n",
    "        cpu_temporal_sample[i],\n",
    "        cpu_temporal_sample[i])\n",
    "    mem_temporal_correlations[i] = ccf(\n",
    "        mem_temporal_sample[i],\n",
    "        mem_temporal_sample[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Have a look at the average temporal correlation for each time shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "zero_shift_timestamp = no_of_timestamps-1\n",
    "days_to_minutes = 24*60\n",
    "daily_vertical_range = [0, 1]\n",
    "weekly_vertical_range = [-0.1, 0.5]\n",
    "for correlations in temporal_correlations:\n",
    "    avg_correlation = np.average(temporal_correlations[correlations], axis=0)\n",
    "\n",
    "    # Demonstrate daily periodicity.\n",
    "\n",
    "    # One unit of time equals 5 minutes.\n",
    "    time_window = (\n",
    "        zero_shift_timestamp - 4 * days_to_minutes // 5,\n",
    "        zero_shift_timestamp + 4 * days_to_minutes // 5)\n",
    "    plt.subplot(len(temporal_correlations), 2, i).plot(\n",
    "        # One unit of time equals 5 minutes.\n",
    "        [5 * (x - zero_shift_timestamp) / days_to_minutes\n",
    "         for x in range(len(avg_correlation))][time_window[0]:time_window[1]],\n",
    "        avg_correlation[time_window[0]:time_window[1]], '-',\n",
    "        # zero time-shift\n",
    "        2*[0], daily_vertical_range, '--',\n",
    "        # +/- a few days\n",
    "        2*[1], daily_vertical_range, '--',\n",
    "        2*[-1], daily_vertical_range, '--',\n",
    "        2*[2], daily_vertical_range, '--',\n",
    "        2*[-2], daily_vertical_range, '--',\n",
    "        2*[3], daily_vertical_range, '--',\n",
    "        2*[-3], daily_vertical_range, '--')\n",
    "    plt.title(correlations + ' Daily Periodicity')\n",
    "    plt.xlabel('Time-shift (Days)')\n",
    "    plt.ylabel('Cross-correlation')\n",
    "    i += 1\n",
    "    \n",
    "    # Demonstrate weekly periodicity.\n",
    "\n",
    "    # One unit of time equals 5 minutes.\n",
    "    time_window = (\n",
    "        zero_shift_timestamp - 4 * 7 * days_to_minutes // 5,\n",
    "        zero_shift_timestamp + 4 * 7 * days_to_minutes // 5)\n",
    "    smoothed = ss.medfilt(avg_correlation, kernel_size=249)\n",
    "    plt.subplot(len(temporal_correlations), 2, i).plot(\n",
    "        # One unit of time equals 5 minutes.\n",
    "        [5 * (x - zero_shift_timestamp) / (7 * days_to_minutes)\n",
    "         for x in range(len(smoothed))][time_window[0]:time_window[1]],\n",
    "        smoothed[time_window[0]:time_window[1]], '-',\n",
    "        # zero time-shift\n",
    "        2*[0], weekly_vertical_range, '--',\n",
    "        # +/- a few weeks\n",
    "        2*[1], weekly_vertical_range, '--',\n",
    "        2*[-1], weekly_vertical_range, '--',\n",
    "        2*[2], weekly_vertical_range, '--',\n",
    "        2*[-2], weekly_vertical_range, '--',\n",
    "        2*[3], weekly_vertical_range, '--',\n",
    "        2*[-3], weekly_vertical_range, '--')\n",
    "    plt.title(correlations + ' Weekly Periodicity')\n",
    "    plt.xlabel('Time-shift (Weeks)')\n",
    "    plt.ylabel('Cross-correlation')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for correlations in temporal_correlations:\n",
    "    avg_correlation = np.average(temporal_correlations[correlations], axis=0)\n",
    "    print(correlations, 'Average Correlation:', np.average(avg_correlation))\n",
    "    print(correlations, 'RMS Correlation:',\n",
    "          np.sqrt(np.mean(avg_correlation**2)))\n",
    "    plt.hist(avg_correlation, bins=[n/10 for n in range(-10, 11)])\n",
    "    plt.title(correlations + ' Temporal Correlations')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
